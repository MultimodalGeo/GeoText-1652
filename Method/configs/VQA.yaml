train_file: ['data/finetune/vqa_train.json',
             'data/finetune/vqa_val.json',
             'data/finetune/vg_qa.json']
             
test_file: ['data/finetune/vqa_test.json']
answer_list: 'data/finetune/answer_list.json'

vqa_root: 'images/coco/'
vg_root: 'images/visualgenome/'

## Vision Encoder
vision_config: 'configs/config_swinB_384.json'

use_clip_vit: False
#image_res: 384
#patch_size: 16

use_swin: True
image_res: 384
patch_size: 32

## Text Encoder
use_roberta: False
text_config: 'configs/config_bert.json'  # ['configs/config_bert.json', 'configs/config_roberta.json']
text_encoder: '/storage_fast/mchu/Multi-model/VLM/X-VLM/data/bert'  # ['data/bert-base-uncased', 'data/roberta-base']


## Training
num_dec_layers: 6
batch_size_train: 24
batch_size_test: 32
max_tokens: 40
k_test: 128


## Other Settings
optimizer: {opt: adamW, lr: 5e-5, weight_decay: 0.01, lr_mult: 2}
schedular: {sched: linear, lr: 5e-5, epochs: 10, num_warmup_steps: 0.1}
start_eval: 7  # epoch index

